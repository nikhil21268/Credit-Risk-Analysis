{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-10-09T11:47:37.021529Z",
          "iopub.status.busy": "2023-10-09T11:47:37.021091Z",
          "iopub.status.idle": "2023-10-09T11:47:37.040706Z",
          "shell.execute_reply": "2023-10-09T11:47:37.039477Z",
          "shell.execute_reply.started": "2023-10-09T11:47:37.021499Z"
        },
        "id": "oOaOkyrGn1G_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# from google.colab import files\n",
        "\n",
        "\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "AhfuDbN9iir8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PonnCy_5n1HB"
      },
      "source": [
        "\n",
        "<center>\n",
        "<img src=\"https://img.freepik.com/free-vector/hand-drawn-credit-assessment-concept_23-2149171651.jpg?w=826&t=st=1696577229~exp=1696577829~hmac=0911770c6527afbc6aab79d46c29179e76904e73fc99488c18268917187def41\" width=800 >\n",
        "</center>\n",
        "<div style=\"padding: 20px;\n",
        "            color: #435334;\n",
        "            margin: 10px;\n",
        "            font-size: 150%;\n",
        "            display: fill;\n",
        "            border-radius: 10px;\n",
        "            border-style: solid;\n",
        "            border-color: #176B87;\n",
        "            background-color: #A7EDE7;\n",
        "            overflow: hidden;\n",
        "            font-weight: 700;\n",
        "            text-align: center;\">\n",
        "Credit Risk Assessment\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FX-5xy3-n1HC"
      },
      "source": [
        "# Table of Contents <a class='anchor' id='top'></a>\n",
        "\n",
        "1. [Introduction üìù](#t1)\n",
        "   - 1.1 [Business Understanding üè¢](#t11)\n",
        "     - 1.1.1 [Define the Problem Statement](#t111)\n",
        "     - 1.1.2 [Identify Stakeholders](#t112)\n",
        "   - 1.2 [Business Objective üéØ](#t12)\n",
        "     - 1.2.1 [Set Clear Goals](#t121)\n",
        "     - 1.2.2 [Define Success Metrics](#t122)\n",
        "\n",
        "2. [EDA üîç](#t2)\n",
        "   - 2.1 [Importing Libraries üìö](#t21)\n",
        "   - 2.2 [Exploring Dataset üìä](#t22)\n",
        "     - 2.2.1 [Data Overview](#t221)\n",
        "     - 2.2.2 [Data Visualization](#t222)\n",
        "\n",
        "3. [Preprocessing and Feature Engineering üõ†Ô∏è](#t3)\n",
        "   - 3.1 [Data Cleaning](#t31)\n",
        "   - 3.2 [Handling Missing Values](#t32)\n",
        "   - 3.3 [Feature Selection](#t33)\n",
        "   - 3.4 [Feature Engineering Techniques](#t34)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-07T05:25:24.112599Z",
          "iopub.status.busy": "2023-10-07T05:25:24.111842Z",
          "iopub.status.idle": "2023-10-07T05:25:24.120127Z",
          "shell.execute_reply": "2023-10-07T05:25:24.118767Z",
          "shell.execute_reply.started": "2023-10-07T05:25:24.112559Z"
        },
        "id": "GmotqfQRn1HD"
      },
      "source": [
        "<div style=\"padding: 10px;\n",
        "            color: #435334;\n",
        "            margin: 10px;\n",
        "            font-size: 150%;\n",
        "            display: fill;\n",
        "            border-radius: 10px;\n",
        "            border-style: solid;\n",
        "            border-color: #176B87;\n",
        "            background-color: #C7E9B0;\n",
        "            overflow: hidden;\n",
        "            font-weight: 700;\n",
        "            text-align: center;\" id = \"t1\">\n",
        "Introduction\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FO9nqcVn1HE"
      },
      "source": [
        "<div style=\"padding: 10px;\n",
        "            color: #435334;\n",
        "            margin: 10px;\n",
        "            font-size: 150%;\n",
        "            display: fill;\n",
        "            border-radius: 10px;\n",
        "            border-style: solid;\n",
        "            border-color: #176B87;\n",
        "            background-color: #C7E9B0;\n",
        "            overflow: hidden;\n",
        "            font-weight: 700;\n",
        "            text-align: center;\" id =\"t2\">\n",
        "Data Cleaning & Pre-Processing\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd1rWPCdn1HF"
      },
      "source": [
        "## 2.1 Importing Libraries <a class='anchor' id='t21'></a> üìö[‚Üë](#top)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "execution": {
          "iopub.execute_input": "2023-10-09T11:47:37.043228Z",
          "iopub.status.busy": "2023-10-09T11:47:37.042873Z",
          "iopub.status.idle": "2023-10-09T11:47:37.051300Z",
          "shell.execute_reply": "2023-10-09T11:47:37.050250Z",
          "shell.execute_reply.started": "2023-10-09T11:47:37.043200Z"
        },
        "id": "WSajxBcmn1HG",
        "outputId": "908301af-c77f-43b0-daac-d829fa11fb83",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Import NumPy for numerical operations\n",
        "import numpy as np\n",
        "# Import Matplotlib for data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "# Import pandas for data manipulation and analysis\n",
        "import pandas as pd\n",
        "# Import Seaborn for enhanced data visualization\n",
        "import seaborn as sns\n",
        "# Import Plotly for interactive data visualization\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as pyo\n",
        "# Import pprint for pretty-printing data structures\n",
        "import pprint\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from plotly.offline import init_notebook_mode\n",
        "init_notebook_mode(connected=True)\n",
        "#This allows the use of Plotly's visualization features in the notebook\n",
        "#without having to connect to the Plotly cloud service."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x52fFbn1n1HG"
      },
      "source": [
        "## 2.2 Exploring Dataset <a class='anchor' id='t22'></a> üìä[‚Üë](#top)\n",
        "\n",
        "<div style=\"float: right; padding: 10px;\">\n",
        "  <img src=\"https://media.giphy.com/media/l2Sqd3jnE4QEyOPM4/giphy.gif\" width=\"500\" height=\"auto\" />\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "execution": {
          "iopub.execute_input": "2023-10-09T11:47:37.053498Z",
          "iopub.status.busy": "2023-10-09T11:47:37.053121Z",
          "iopub.status.idle": "2023-10-09T11:49:13.040938Z",
          "shell.execute_reply": "2023-10-09T11:49:13.039570Z",
          "shell.execute_reply.started": "2023-10-09T11:47:37.053464Z"
        },
        "id": "ciAhInbQn1HH",
        "outputId": "406dfb22-4a35-4fb3-cd6b-014eec72dc9b",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "ParserError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4a29853b2f6b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# df = pd.read_csv(\"/kaggle/input/lending-club/accepted_2007_to_2018Q4.csv.gz\",compression='gzip',low_memory=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df = pd.read_csv(\"accepted_2007_to_2018Q4.csv\",low_memory=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/ML_Dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1776\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1778\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1779\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
          ]
        }
      ],
      "source": [
        "# Reading the dataset .csv file\n",
        "# Add low_memory=False if there are RAM limitations\n",
        "# df = pd.read_csv(\"/kaggle/input/lending-club/accepted_2007_to_2018Q4.csv.gz\",compression='gzip',low_memory=False)\n",
        "#df = pd.read_csv(\"accepted_2007_to_2018Q4.csv\",low_memory=False)\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/ML_Dataset.csv\")\n",
        "df = df.iloc[:50000]\n",
        "\n",
        "# path=\"/content/drive/MyDrive/Colab Notebooks/ML_Dataset.csv\"\n",
        "# df = pd.read_csv(path,low_memory=True)\n",
        "# df = df.iloc[:50000]\n",
        "\n",
        "# Takes some time because of the size of file\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--0ys2hEvlTc"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-10-09T11:49:13.044234Z",
          "iopub.status.busy": "2023-10-09T11:49:13.043917Z",
          "iopub.status.idle": "2023-10-09T11:49:13.050401Z",
          "shell.execute_reply": "2023-10-09T11:49:13.048902Z",
          "shell.execute_reply.started": "2023-10-09T11:49:13.044209Z"
        },
        "id": "aUvh78Wxn1HI",
        "outputId": "dc12eda8-98fe-49e4-c3f9-197fa67bceb3",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataframe shape : (2798, 151)\n"
          ]
        }
      ],
      "source": [
        "# Printing shape of dataframe\n",
        "print(\"Dataframe shape :\",df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QEeuoCLn1HJ"
      },
      "source": [
        "### 2.21 Exploring Missing Data <a class='anchor' id='t221'></a> ‚ö†Ô∏è[‚Üë](#top)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T11:49:13.052149Z",
          "iopub.status.busy": "2023-10-09T11:49:13.051830Z",
          "iopub.status.idle": "2023-10-09T11:49:16.797912Z",
          "shell.execute_reply": "2023-10-09T11:49:16.796898Z",
          "shell.execute_reply.started": "2023-10-09T11:49:13.052121Z"
        },
        "id": "Zh66oYzBn1HJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Calculate missing data percentages\n",
        "missing_data_percentage = df.isnull().mean().sort_values(ascending=False) * 100\n",
        "\n",
        "# Create a Plotly bar plot\n",
        "fig = px.bar(x=missing_data_percentage.index, y=missing_data_percentage.values,\n",
        "             labels={'x': 'Columns', 'y': 'Missing Percentage'},\n",
        "             title='Missing Data Percentage by Column',\n",
        "             color_discrete_sequence=px.colors.qualitative.Pastel)\n",
        "\n",
        "# Customize the layout\n",
        "fig.update_layout(\n",
        "    xaxis_title_text='Columns',\n",
        "    yaxis_title_text='Missing Percentage',\n",
        "    xaxis_title_font_size=16,\n",
        "    yaxis_title_font_size=16,\n",
        "    title_font_size=20,\n",
        "    showlegend=False,  # Hide the legend\n",
        "    yaxis_tickvals=list(range(0, 101, 20)),  # Set Y-axis tick values at 0, 20, 40, 60, 80, and 100\n",
        ")\n",
        "\n",
        "# Add column number with name\n",
        "fig.update_xaxes(tickvals=list(range(len(missing_data_percentage))), ticktext=[f\"{i+1}: {col}\" for i, col in enumerate(missing_data_percentage.index)])\n",
        "# Add a straight black line at y=20\n",
        "fig.add_shape(\n",
        "    type='line',\n",
        "    x0=-0.5,  # Start from the left-most edge of the plot\n",
        "    x1=len(missing_data_percentage) - 0.5,  # Extend to the right-most edge of the plot\n",
        "    y0=20,\n",
        "    y1=20,\n",
        "    line=dict(color='green', width=2),\n",
        ")\n",
        "# Show the plot\n",
        "fig.show()\n",
        "# fig.show(renderer='iframe_connected')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T11:49:16.800212Z",
          "iopub.status.busy": "2023-10-09T11:49:16.799364Z",
          "iopub.status.idle": "2023-10-09T11:49:18.161665Z",
          "shell.execute_reply": "2023-10-09T11:49:18.160426Z",
          "shell.execute_reply.started": "2023-10-09T11:49:16.800176Z"
        },
        "id": "f6H32ngBn1HJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define a threshold for missing data (e.g., 20%)\n",
        "threshold = 20\n",
        "# Get columns to drop and their size\n",
        "columns_to_drop = missing_data_percentage[missing_data_percentage > threshold].index\n",
        "columns_to_drop_size = len(columns_to_drop)\n",
        "\n",
        "# Get columns to keep and their size\n",
        "columns_to_keep = missing_data_percentage[missing_data_percentage <= threshold].index\n",
        "columns_to_keep_size = len(columns_to_keep)\n",
        "\n",
        "# Update the DataFrame to keep only columns with less than or equal to 20% missing data\n",
        "filtered_df1 = df[columns_to_keep]\n",
        "\n",
        "# Print columns to drop in a single line\n",
        "print(f\"Columns to Drop ({columns_to_drop_size}): {', '.join(columns_to_drop)}\")\n",
        "print(\"\\n\")\n",
        "# Print columns to keep in a single line\n",
        "print(f\"Columns to Keep ({columns_to_keep_size}): {', '.join(columns_to_keep)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-50j-3tn1HJ"
      },
      "source": [
        "### Selected Features for Credit Risk Analysis ‚òëÔ∏è\n",
        "In our credit risk analysis, we've meticulously chosen a subset of features from the LendingClub dataset based on their relevance and definitions from the LC dictionary. These features offer valuable insights into borrowers, loan characteristics, and financial history. To maintain the integrity of our analysis and prevent data leakage, we've focused on features that are available at the time of loan origination. This approach aligns with the fact that lenders wouldn't have access to certain details until after the loan is issued, ensuring our assessments remain accurate and secure.\n",
        "We will further analyze these features to determine whether they should be retained in our analysis.\n",
        "\n",
        "Here is the list of selected features along with their definitions:\n",
        "\n",
        "| Feature Name             | Definition                                                                                        |\n",
        "|--------------------------|--------------------------------------------------------------------------------------------------|\n",
        "| `loan_amnt`              | The listed amount of the loan applied for by the borrower.                                       |\n",
        "| `term`                   | The number of payments on the loan in months (either 36 or 60).                                   |\n",
        "| `int_rate`               | The interest rate on the loan.                                                                    |\n",
        "| `installment`            | The monthly payment owed by the borrower if the loan originates.                                 |\n",
        "| `grade`                  | LendingClub assigned loan grade.                                                                  |\n",
        "| `sub_grade`              | LendingClub assigned loan subgrade.                                                              |\n",
        "| `emp_title`              | The job title supplied by the borrower when applying for the loan.                                |\n",
        "| `emp_length`             | Employment length in years, ranging from 0 (less than one year) to 10 (ten or more years).        |\n",
        "| `home_ownership`         | The home ownership status provided by the borrower (e.g., RENT, OWN, MORTGAGE, OTHER).           |\n",
        "| `annual_inc`             | The self-reported annual income provided by the borrower during registration.                     |\n",
        "| `verification_status`    | Indicates if income was verified by LendingClub or not, or if the income source was verified.    |\n",
        "| `issue_d`                | The month in which the loan was funded.                                                           |\n",
        "| `loan_status`            | The current status of the loan (e.g., Fully Paid, Charged Off).                                     |\n",
        "| `purpose`                | A category provided by the borrower for the loan request.                                         |\n",
        "| `title`                  | The loan title provided by the borrower.                                                           |\n",
        "| `zip_code`               | The first 3 numbers of the zip code provided by the borrower in the loan application.             |\n",
        "| `addr_state`             | The state provided by the borrower in the loan application.                                       |\n",
        "| `dti`                    | A ratio calculated using the borrower‚Äôs total monthly debt payments divided by their monthly income, excluding mortgage and the requested LC loan. |\n",
        "| `earliest_cr_line`       | The month when the borrower's earliest reported credit line was opened.                            |\n",
        "| `open_acc`               | The number of open credit lines in the borrower's credit file.                                      |\n",
        "| `pub_rec`                | Number of derogatory public records.                                                                |\n",
        "| `revol_bal`              | Total credit revolving balance.                                                                    |\n",
        "| `revol_util`             | Revolving line utilization rate, or the amount of credit the borrower is using relative to all available revolving credit. |\n",
        "| `total_acc`              | The total number of credit lines currently in the borrower's credit file.                             |\n",
        "| `initial_list_status`    | The initial listing status of the loan (possible values: 'W' for whole loans or 'F' for fractional loans). |\n",
        "| `application_type`       | Indicates whether the loan is an individual application or a joint application with two co-borrowers.  |\n",
        "| `mort_acc`               | Number of mortgage accounts.                                                                        |\n",
        "| `pub_rec_bankruptcies`   | Number of public record bankruptcies.                                                               |\n",
        "| `fico_range_high`        | The upper boundary range the borrower‚Äôs FICO at loan origination belongs to.                       |\n",
        "| `fico_range_low`         | The lower boundary range the borrower‚Äôs FICO at loan origination belongs to.                      |\n",
        "<!-- | `inq_last_6mths`         | The number of inquiries in the last 6 months.                                                     |\n",
        "| `total_bal_il`           | Total current balance of all installment accounts.                                               |\n",
        "| `mths_since_recent_bc`   | Months since most recent bank card account opened.                                                |\n",
        "| `num_rev_accts`          | Number of revolving accounts.                                                                     |\n",
        "| `mo_sin_old_il_acct`     | Months since oldest bank installment account opened. This could be an important factor in creditworthiness. |\n",
        "| `mo_sin_old_rev_tl_op`   | Months since oldest revolving account opened. This is a key metric in credit scoring models.   |\n",
        "| `mo_sin_rcnt_rev_tl_op`  | Months since most recent revolving account opened.                                                |\n",
        "| `mo_sin_rcnt_tl`         | Months since most recent account opened.                                                          |\n",
        "| `bc_util`                | Ratio of total current balance to high credit/credit limit for all bankcard accounts.          |\n",
        "| `pct_tl_nvr_dlq`         | Percent of trades never delinquent.                                                               |\n",
        "| `avg_cur_bal`            | Average current balance of all accounts.   -->\n",
        "\n",
        "These carefully selected features provide a solid foundation for evaluating credit risk and making informed decisions in the loan origination process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T11:49:18.163923Z",
          "iopub.status.busy": "2023-10-09T11:49:18.163109Z",
          "iopub.status.idle": "2023-10-09T11:49:18.543836Z",
          "shell.execute_reply": "2023-10-09T11:49:18.542670Z",
          "shell.execute_reply.started": "2023-10-09T11:49:18.163894Z"
        },
        "id": "5I5hEt-3n1HK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define a list of the selected columns\n",
        "selected_columns = [\n",
        "    'loan_amnt', 'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title',\n",
        "    'emp_length', 'home_ownership', 'annual_inc', 'verification_status', 'issue_d',\n",
        "    'loan_status', 'purpose', 'title', 'zip_code', 'addr_state', 'dti', 'earliest_cr_line',\n",
        "    'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'initial_list_status',\n",
        "    'application_type', 'mort_acc','pub_rec_bankruptcies','fico_range_high', 'fico_range_low'\n",
        "]\n",
        "\n",
        "# selected_columns = [\n",
        "#     'loan_amnt', 'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title',\n",
        "#     'emp_length', 'home_ownership', 'annual_inc', 'verification_status', 'issue_d',\n",
        "#     'loan_status', 'purpose', 'title', 'zip_code', 'addr_state', 'dti', 'earliest_cr_line',\n",
        "#     'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc', 'initial_list_status',\n",
        "#     'application_type', 'mort_acc', 'pub_rec_bankruptcies', 'fico_range_high', 'fico_range_low',\n",
        "#     'inq_last_6mths', 'total_bal_il', 'mths_since_recent_bc', 'num_rev_accts',\n",
        "#     'mo_sin_old_il_acct', 'mo_sin_old_rev_tl_op', 'mo_sin_rcnt_rev_tl_op',\n",
        "#     'mo_sin_rcnt_tl', 'bc_util', 'pct_tl_nvr_dlq', 'avg_cur_bal'\n",
        "# ]\n",
        "\n",
        "\n",
        "# Select the specified columns from the DataFrame\n",
        "filtered_df2 = filtered_df1[selected_columns]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgsR95ZLn1HK"
      },
      "source": [
        "### Target Column Values üîΩ\n",
        "\n",
        "For credit risk detection and analysis, our focus is on completed loans, where we distinguish between those that have been fully paid (representing low credit risk) and those that have charged off (indicating high credit risk). To ensure the accuracy and relevance of our analysis, we are selective about which loans to include:\n",
        "\n",
        "- **Conclusive Outcomes**: We concentrate on loans that have reached a conclusive outcome; these loans are no longer in progress.\n",
        "\n",
        "- **Distinguishing Factors**: Our goal is to identify the key features that distinguish between loans with low credit risk (fully paid) and high credit risk (charged off).\n",
        "\n",
        "- **Excluding Ongoing Loans**: Loans that are still in progress (e.g., \"current\") are excluded from our analysis because their final status remains uncertain.\n",
        "\n",
        "- **Avoiding Credit Policy Exceptions**: Loans that do not meet the credit policy are also excluded, as they represent specific credit issues that may not apply broadly.\n",
        "\n",
        "- **Data Completeness**: Loans with missing status information are not considered in our analysis. We require complete data to make accurate credit risk assessments.\n",
        "\n",
        "This refined approach ensures that our analysis is laser-focused on the essential aspects for credit risk detection. It enables us to pinpoint the factors that contribute to successful loan repayment and those that lead to defaults or charge-offs.\n",
        "\n",
        "**Note** : Generally speaking, a Default occurs when a borrower fails to make payments beyond a certain timeframe, resulting in the lender working with a third party to collect the remaining debt. In contrast, 'Charged Off' represents the worst-case scenario, where no further payments are expected, making it the focus of our prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T11:49:18.545587Z",
          "iopub.status.busy": "2023-10-09T11:49:18.545221Z",
          "iopub.status.idle": "2023-10-09T11:49:18.967063Z",
          "shell.execute_reply": "2023-10-09T11:49:18.965951Z",
          "shell.execute_reply.started": "2023-10-09T11:49:18.545558Z"
        },
        "id": "usmWX_5Dn1HL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define the target statuses to keep\n",
        "target_statuses = ['Fully Paid', 'Charged Off']\n",
        "\n",
        "# Filter the DataFrame to include only loans with target statuses\n",
        "filtered_df3 = filtered_df2[filtered_df2['loan_status'].isin(target_statuses)]\n",
        "\n",
        "# Verify the resulting dataset\n",
        "print(filtered_df3['loan_status'].value_counts())\n",
        "print(\"new shape: \",filtered_df3.shape)\n",
        "# from ~2m to ~1m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T11:49:18.969457Z",
          "iopub.status.busy": "2023-10-09T11:49:18.968783Z",
          "iopub.status.idle": "2023-10-09T11:49:19.995787Z",
          "shell.execute_reply": "2023-10-09T11:49:19.994872Z",
          "shell.execute_reply.started": "2023-10-09T11:49:18.969416Z"
        },
        "id": "9KRTSD3_n1HM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "filtered_df3.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T11:49:19.999320Z",
          "iopub.status.busy": "2023-10-09T11:49:19.998910Z",
          "iopub.status.idle": "2023-10-09T11:49:21.151383Z",
          "shell.execute_reply": "2023-10-09T11:49:21.149943Z",
          "shell.execute_reply.started": "2023-10-09T11:49:19.999284Z"
        },
        "id": "d0RwgrpAn1HM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# List of columns with categorical data\n",
        "categorical_columns = ['term', 'grade', 'sub_grade', 'emp_title', 'emp_length',\n",
        "                        'home_ownership', 'verification_status', 'issue_d',\n",
        "                        'loan_status', 'purpose', 'title', 'zip_code',\n",
        "                        'addr_state', 'earliest_cr_line', 'initial_list_status',\n",
        "                        'application_type']\n",
        "\n",
        "# Print unique value counts for each categorical column\n",
        "for column in categorical_columns:\n",
        "    unique_value_count = filtered_df3[column].nunique()\n",
        "    print(f\"Unique value count for column '{column}': {unique_value_count}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T11:54:58.711116Z",
          "iopub.status.busy": "2023-10-09T11:54:58.710654Z",
          "iopub.status.idle": "2023-10-09T11:57:23.537263Z",
          "shell.execute_reply": "2023-10-09T11:57:23.536452Z",
          "shell.execute_reply.started": "2023-10-09T11:54:58.711086Z"
        },
        "id": "N-2eSMLyn1HN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Dividing our features into categorical and numerical\n",
        "categorical=[feature for feature in filtered_df3.columns if filtered_df3[feature].dtype=='object']\n",
        "numerical=[feature for feature in filtered_df3.columns if feature not in categorical]\n",
        "\n",
        "# Print out the numerical features\n",
        "print(numerical)\n",
        "\n",
        "# Histplot for each variable in numerical list\n",
        "def histplot_visual(data,column):\n",
        "    fig, ax = plt.subplots(3,5,figsize=(15,6))\n",
        "    fig.suptitle('Histplot for each variable',y=1, size=20)\n",
        "    ax=ax.flatten()\n",
        "    for i,feature in enumerate(column):\n",
        "        # if i < 14:\n",
        "            # print(i)\n",
        "        sns.histplot(data=data[feature],ax=ax[i], kde=True)\n",
        "histplot_visual(data=filtered_df3,column=numerical)\n",
        "plt.tight_layout()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T11:57:34.009585Z",
          "iopub.status.busy": "2023-10-09T11:57:34.009227Z",
          "iopub.status.idle": "2023-10-09T11:57:44.338061Z",
          "shell.execute_reply": "2023-10-09T11:57:44.336943Z",
          "shell.execute_reply.started": "2023-10-09T11:57:34.009555Z"
        },
        "id": "0Wc1YQHkn1HN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Boxplot for each variable in numerical list\n",
        "def boxplots_visual(data,column):\n",
        "    # fig, ax = plt.subplots(3,5,size=(15,6))\n",
        "    fig, ax = plt.subplots(3,5,figsize=(15,6))\n",
        "    fig.suptitle('Boxplot for each variable',y=1, size=20)\n",
        "    ax=ax.flatten()\n",
        "    for i,feature in enumerate(column):\n",
        "        sns.boxplot(data=data[feature],ax=ax[i], orient='h')\n",
        "        ax[i].set_title(feature+ ', skewness is: '+str(round(data[feature].skew(axis = 0, skipna = True),2)),fontsize=10)\n",
        "        ax[i].set_xlim([min(data[feature]), max(data[feature])])\n",
        "boxplots_visual(data=filtered_df3,column=numerical)\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T12:33:40.838477Z",
          "iopub.status.busy": "2023-10-09T12:33:40.836856Z",
          "iopub.status.idle": "2023-10-09T12:33:40.951644Z",
          "shell.execute_reply": "2023-10-09T12:33:40.950262Z",
          "shell.execute_reply.started": "2023-10-09T12:33:40.838354Z"
        },
        "id": "xgy5vZGPn1HO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "filtered_df3['home_ownership'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T12:54:41.137120Z",
          "iopub.status.busy": "2023-10-09T12:54:41.135612Z",
          "iopub.status.idle": "2023-10-09T12:54:41.188945Z",
          "shell.execute_reply": "2023-10-09T12:54:41.187862Z",
          "shell.execute_reply.started": "2023-10-09T12:54:41.137069Z"
        },
        "id": "-xlpxF1_n1HO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "filtered_df3['emp_length'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T13:42:48.442985Z",
          "iopub.status.busy": "2023-10-09T13:42:48.441667Z",
          "iopub.status.idle": "2023-10-09T13:42:53.428615Z",
          "shell.execute_reply": "2023-10-09T13:42:53.427209Z",
          "shell.execute_reply.started": "2023-10-09T13:42:48.442946Z"
        },
        "id": "az1lJLlmn1HO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Create a copy of filtered_df3\n",
        "filtered_df4 = filtered_df3.copy()\n",
        "\n",
        "# Step 1: Remove 'emp_title' and 'title' columns\n",
        "filtered_df4.drop(['emp_title', 'title'], axis=1, inplace=True)\n",
        "\n",
        "# Step 2: Calculate and keep the average FICO score\n",
        "filtered_df4['fico_score_avg'] = 0.5 * filtered_df4['fico_range_low'] + 0.5 * filtered_df4['fico_range_high']\n",
        "filtered_df4.drop(['fico_range_high', 'fico_range_low'], axis=1, inplace=True)\n",
        "\n",
        "# Step 3: Clean 'term' column\n",
        "filtered_df4['term'] = filtered_df4['term'].str.replace(' months', '').str.strip().astype('int64')\n",
        "\n",
        "\n",
        "\n",
        "# Step 5: Map 'loan_status' to binary values\n",
        "filtered_df4['loan_status'] = filtered_df4['loan_status'].map({'Fully Paid': 0, 'Charged Off': 1})\n",
        "# step 4\n",
        "# Create a mapping for 'emp_length'\n",
        "emp_length_mapping = {\n",
        "    '10+ years': 10,\n",
        "    '9 years': 9,\n",
        "    '8 years': 8,\n",
        "    '7 years': 7,\n",
        "    '6 years': 6,\n",
        "    '5 years': 5,\n",
        "    '4 years': 4,\n",
        "    '3 years': 3,\n",
        "    '2 years': 2,\n",
        "    '1 year': 1,\n",
        "    '< 1 year': 0,  # Treat '< 1 year' as 0 years of employment\n",
        "}\n",
        "\n",
        "# Apply the mapping to 'emp_length' column\n",
        "filtered_df4['emp_length'] = filtered_df4['emp_length'].map(emp_length_mapping)\n",
        "# Step 6: Drop 'grade' column and map 'sub_grade'\n",
        "filtered_df4.drop('grade', axis=1, inplace=True)\n",
        "filtered_df4['sub_grade'] = filtered_df4['sub_grade'].map({'A1': 0, 'A2': 1, 'A3': 2, 'A4': 3, 'A5': 4,\n",
        "                                                          'B1': 5, 'B2': 6, 'B3': 7, 'B4': 8, 'B5': 9,\n",
        "                                                          'C1': 10, 'C2': 11, 'C3': 12, 'C4': 13, 'C5': 14,\n",
        "                                                          'D1': 15, 'D2': 16, 'D3': 17, 'D4': 18, 'D5': 19,\n",
        "                                                          'E1': 20, 'E2': 21, 'E3': 22, 'E4': 23, 'E5': 24,\n",
        "                                                          'F1': 25, 'F2': 26, 'F3': 27, 'F4': 28, 'F5': 29,\n",
        "                                                          'G1': 30, 'G2': 31, 'G3': 32, 'G4': 33, 'G5': 34})\n",
        "\n",
        "# Step 7: Replace 'NONE' and 'ANY' in 'home_ownership' with 'OTHER'\n",
        "filtered_df4['home_ownership'] = filtered_df4['home_ownership'].replace(['NONE', 'ANY'], 'OTHER')\n",
        "\n",
        "# Step 8: Drop 'issue_d' column\n",
        "filtered_df4.drop('issue_d', axis=1, inplace=True)\n",
        "\n",
        "# Extract the year from 'earliest_cr_line' and convert to numeric\n",
        "filtered_df4['earliest_cr_line'] = filtered_df4['earliest_cr_line'].apply(lambda x: int(x[-4:]) if pd.notnull(x) else x)\n",
        "\n",
        "# Drop 'zip_code' column\n",
        "filtered_df4.drop('zip_code', axis=1, inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T13:42:56.196078Z",
          "iopub.status.busy": "2023-10-09T13:42:56.195669Z",
          "iopub.status.idle": "2023-10-09T13:42:56.227881Z",
          "shell.execute_reply": "2023-10-09T13:42:56.226586Z",
          "shell.execute_reply.started": "2023-10-09T13:42:56.196049Z"
        },
        "id": "Nja6Dfh8n1HO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Display the first few rows of the preprocessed DataFrame\n",
        "filtered_df4.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T13:42:58.439600Z",
          "iopub.status.busy": "2023-10-09T13:42:58.439049Z",
          "iopub.status.idle": "2023-10-09T13:42:58.838370Z",
          "shell.execute_reply": "2023-10-09T13:42:58.837143Z",
          "shell.execute_reply.started": "2023-10-09T13:42:58.439569Z"
        },
        "id": "YOInx_ykn1HO",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "filtered_df4.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T13:43:01.315319Z",
          "iopub.status.busy": "2023-10-09T13:43:01.314975Z",
          "iopub.status.idle": "2023-10-09T13:43:02.287549Z",
          "shell.execute_reply": "2023-10-09T13:43:02.286207Z",
          "shell.execute_reply.started": "2023-10-09T13:43:01.315293Z"
        },
        "id": "AnMJATt_n1HP",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Print the percentage of missing values for each feature\n",
        "for column in filtered_df4.columns:\n",
        "    missing = filtered_df4[column].isna().sum()\n",
        "    portion = (missing / filtered_df4.shape[0]) * 100\n",
        "    print(f\"'{column}': number of missing values '{missing}' ==> '{portion:.3f}%'\")\n",
        "\n",
        "# Remove rows with missing values\n",
        "filtered_df4.dropna(inplace=True)\n",
        "\n",
        "# Display the first few rows of the preprocessed DataFrame after removing missing values\n",
        "filtered_df4.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T13:43:04.683657Z",
          "iopub.status.busy": "2023-10-09T13:43:04.683258Z",
          "iopub.status.idle": "2023-10-09T13:43:05.052102Z",
          "shell.execute_reply": "2023-10-09T13:43:05.050937Z",
          "shell.execute_reply.started": "2023-10-09T13:43:04.683629Z"
        },
        "id": "YP6Mbm52n1HQ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "filtered_df4.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T13:43:14.319929Z",
          "iopub.status.busy": "2023-10-09T13:43:14.319327Z",
          "iopub.status.idle": "2023-10-09T13:43:15.720430Z",
          "shell.execute_reply": "2023-10-09T13:43:15.719073Z",
          "shell.execute_reply.started": "2023-10-09T13:43:14.319901Z"
        },
        "id": "CjhounGgn1HQ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define the list of categorical columns to create dummy variables\n",
        "dummies = ['verification_status', 'purpose', 'initial_list_status', 'application_type', 'home_ownership', 'addr_state']\n",
        "\n",
        "# Create dummy variables and drop the first category in each column\n",
        "filtered_df4 = pd.get_dummies(filtered_df4, columns=dummies, drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T13:43:28.216042Z",
          "iopub.status.busy": "2023-10-09T13:43:28.214828Z",
          "iopub.status.idle": "2023-10-09T13:43:28.388212Z",
          "shell.execute_reply": "2023-10-09T13:43:28.387052Z",
          "shell.execute_reply.started": "2023-10-09T13:43:28.216006Z"
        },
        "id": "mXxQboOTn1HR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "filtered_df4.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-09T13:44:18.480620Z",
          "iopub.status.busy": "2023-10-09T13:44:18.480052Z",
          "iopub.status.idle": "2023-10-09T13:44:45.741204Z",
          "shell.execute_reply": "2023-10-09T13:44:45.739913Z",
          "shell.execute_reply.started": "2023-10-09T13:44:18.480591Z"
        },
        "id": "Ty728g1Cn1HR",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Calculate the correlation matrix\n",
        "correlation_matrix = filtered_df4.corr()\n",
        "\n",
        "# Create a heatmap without percentage values\n",
        "plt.figure(figsize=(22, 20))\n",
        "sns.heatmap(correlation_matrix, cmap=\"viridis\", cbar=True, square=True)\n",
        "plt.title(\"Correlation Heatmap without Percentage Values\", fontsize=16)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2a-yeo6n1HS"
      },
      "outputs": [],
      "source": [
        "# filtered_df4=filtered_df4.iloc[:10000]\n",
        "\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(filtered_df4.loan_status.value_counts())\n",
        "sns.countplot(x='loan_status', data=filtered_df4)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Te_-rzjn1HS"
      },
      "source": [
        "Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtQ_ionbn1HT"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Split the dataset into features (X) and labels (y)\n",
        "# X = df.drop(columns=['Outcome'])\n",
        "# y = df['Outcome']\n",
        "\n",
        "#filtered_df4.drop([\"emp_title\"], axis = 1, inplace = True)\n",
        "\n",
        "X = filtered_df4.drop('loan_status', axis=1)\n",
        "feature_names = X.columns.tolist()\n",
        "y = filtered_df4[['loan_status']]\n",
        "\n",
        "# # Check for missing values\n",
        "# missing_values = filtered_df4.isnull().sum()\n",
        "\n",
        "# # Display columns with missing values\n",
        "# columns_with_missing_values = missing_values[missing_values > 0]\n",
        "# print(columns_with_missing_values)\n",
        "\n",
        "# Example of imputing missing values with the median\n",
        "# df.fillna(df.median(), inplace=True)\n",
        "# df.fillna(df.median(), inplace=True, numeric_only=True)\n",
        "# numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "# df[numeric_cols] = df[numeric_cols].fillna(df.median())\n",
        "# Create a list of numeric columns\n",
        "# numeric_cols = filtered_df4.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# # Fill missing values in numeric columns with median\n",
        "# filtered_df4[numeric_cols] = filtered_df4[numeric_cols].fillna(filtered_df4[numeric_cols].median())\n",
        "\n",
        "\n",
        "df=filtered_df4\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "\n",
        "\n",
        "# # Ensure the 'loan_status' column is numeric\n",
        "# df['loan_status'] = pd.to_numeric(df['loan_status'], errors='coerce')\n",
        "\n",
        "# # Drop rows with missing 'loan_status'\n",
        "# df = df.dropna(subset=['loan_status'])\n",
        "\n",
        "# # Create a list of numeric columns\n",
        "# numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# # Fill missing values in numeric columns with median\n",
        "# df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# # Split the data\n",
        "# X = df.drop('loan_status', axis=1)\n",
        "# y = df['loan_status']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "# # Standardize the features\n",
        "# scaler = StandardScaler()\n",
        "# X_train = scaler.fit_transform(X_train)\n",
        "# X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# # Ensure the 'loan_status' column is numeric\n",
        "# df['loan_status'] = pd.to_numeric(df['loan_status'], errors='coerce')\n",
        "\n",
        "# # Drop rows with missing 'loan_status'\n",
        "# df = df.dropna(subset=['loan_status'])\n",
        "\n",
        "# # Create a list of numeric columns\n",
        "# numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# # Fill missing values in numeric columns with median\n",
        "# df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
        "\n",
        "# # Split the data\n",
        "# X = df.drop('loan_status', axis=1)\n",
        "# y = df['loan_status']\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "# # Standardize the features\n",
        "# scaler = StandardScaler()\n",
        "# X_train = scaler.fit_transform(X_train)\n",
        "# X_test = scaler.transform(X_test)\n",
        "\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn import metrics\n",
        "from sklearn.metrics import classification_report\n",
        "# from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "# from sklearn.metrics import precision_recall_curve\n",
        "# from sklearn.metrics import plot_precision_recall_curve\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "# from sklearn import metrics\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "y_train = y_train.values.ravel()\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = scaler.fit_transform(X_train)\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# logreg = LogisticRegression(max_iter=1000)\n",
        "# logreg.fit(X_train_scaled, y_train)\n",
        "\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "# logreg = LogisticRegression(solver=\"saga\", max_iter=1000)  # L2 regularization\n",
        "\n",
        "logreg.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#,penalty='l2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSFCo9kon1HU"
      },
      "outputs": [],
      "source": [
        "# y_pred = logreg.predict(X_test)\n",
        "# print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
        "\n",
        "# y_pred = logreg.predict(X_test)\n",
        "# print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
        "\n",
        "# Assuming 'model' is your logistic regression model\n",
        "threshold = 0.3  # Adjust the threshold as needed\n",
        "y_pred_proba = logreg.predict_proba(X_test)[:, 1]\n",
        "y_pred = (y_pred_proba > threshold).astype(int)\n",
        "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HLz2BX7n1HV"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XMUFopun1HV"
      },
      "outputs": [],
      "source": [
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# print(df.loan_status.value_counts())\n",
        "# sns.countplot(x='loan_status', data=df)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aumyqbrXn1HV"
      },
      "outputs": [],
      "source": [
        "# logreg_conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "# logreg_conf_matrix\n",
        "\n",
        "# sns.set(rc = {'figure.figsize':(15,8)})\n",
        "# sns.heatmap(logreg_conf_matrix, annot=True, cmap='YlGnBu', linewidths=.29,fmt='d')\n",
        "\n",
        "logreg_conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "total = np.sum(logreg_conf_matrix)\n",
        "\n",
        "percentage_matrix = logreg_conf_matrix / total * 100\n",
        "\n",
        "sns.set(rc = {'figure.figsize':(15,8)})\n",
        "sns.heatmap(percentage_matrix, annot=True, cmap='YlGnBu', fmt='.2f', linewidths=.5)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Vf14MNjn1HW"
      },
      "outputs": [],
      "source": [
        "# cm = confusion_matrix(y_test, y_pred)\n",
        "# #cm = confusion_matrix(y_test, y_pred, normalize='all')\n",
        "# cmd = ConfusionMatrixDisplay(cm, display_labels=['Charged Off','Fully Paid'])\n",
        "# cmd.plot()\n",
        "# cmd.ax_.set(xlabel='Predicted', ylabel='True')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DQDQKMfsn1HW"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XqXc2q-n1HW"
      },
      "outputs": [],
      "source": [
        "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
        "\n",
        "# # Assuming 'model' is your logistic regression model\n",
        "# threshold = 0.3  # Adjust the threshold as needed\n",
        "# y_pred_proba = logreg.predict_proba(X_test)[:, 1]\n",
        "# y_pred = (y_pred_proba > threshold).astype(int)\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('Log_ROC')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUF8WNJfn1HW"
      },
      "outputs": [],
      "source": [
        "print(logit_roc_auc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmSR6reUn1HW"
      },
      "outputs": [],
      "source": [
        "acc_test_LogReg = accuracy_score(y_test, y_pred)\n",
        "prec_test_LogReg = precision_score(y_test, y_pred)\n",
        "rec_test_LogReg = recall_score(y_test, y_pred)\n",
        "print(f'''Accuracy (test): {acc_test_LogReg:.3f}\n",
        "Precision (test): {prec_test_LogReg:.3f}\n",
        "Recall (test): {rec_test_LogReg:.3f}''')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xh-EypLcn1HX"
      },
      "outputs": [],
      "source": [
        "logreg_prob = logreg.predict_proba(X_test)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7RWbnKP4n1HX"
      },
      "outputs": [],
      "source": [
        "precision0_04 = precision_score(y_test, logreg_prob > 0.50)\n",
        "recall0_04 = recall_score(y_test, logreg_prob > 0.50)\n",
        "\n",
        "\n",
        "precision0_04"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAUg1lVvn1HX"
      },
      "outputs": [],
      "source": [
        "# #LogReg curve\n",
        "# disp = plot_precision_recall_curve(logreg, X_test, y_test)\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "# # Compute precision-recall pairs\n",
        "# precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
        "\n",
        "# # Plot the precision-recall curve\n",
        "# plt.plot(recall, precision, marker='.')\n",
        "# plt.xlabel('Recall')\n",
        "# plt.ylabel('Precision')\n",
        "# plt.title('Precision-Recall Curve')\n",
        "# plt.show()\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "\n",
        "# # Compute precision-recall pairs\n",
        "# precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
        "\n",
        "# # Plot the precision-recall curve manually\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.plot(recall, precision, marker='.')\n",
        "# plt.xlabel('Recall')\n",
        "# plt.ylabel('Precision')\n",
        "# plt.title('Precision-Recall Curve (Manual)')\n",
        "\n",
        "# # Generate the precision-recall curve using PrecisionRecallDisplay\n",
        "# pr_display = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
        "# pr_display.plot(ax=plt.gca())\n",
        "\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "# # Assuming y_true contains the true labels and y_scores contains the predicted scores\n",
        "# precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
        "\n",
        "# # Plot the precision-recall curve\n",
        "# plt.plot(recall, precision, marker='.')\n",
        "# plt.xlabel('Recall')\n",
        "# plt.ylabel('Precision')\n",
        "# plt.title('Precision-Recall Curve')\n",
        "# plt.show()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "# Assuming y_test contains the true labels and y_pred contains the predicted labels\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
        "\n",
        "# Calculate the average precision score\n",
        "average_precision = average_precision_score(y_test, y_pred)\n",
        "\n",
        "# Plot the precision-recall curve\n",
        "plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
        "plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
        "\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve (AP={0:.2f})'.format(average_precision))\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTZHlTXwn1HY"
      },
      "source": [
        "Shap Library -\n",
        "\n",
        "`shap` is a Python library for interpreting the output of machine learning models. It stands for SHapley Additive exPlanations. This library helps in understanding the importance and contribution of different features in making predictions.\n",
        "\n",
        "Specifically, `shap` provides a unified approach to compute Shapley values, which are a concept from cooperative game theory. In the context of machine learning, Shapley values represent the average contribution of a feature value towards the prediction across all possible combinations of features.\n",
        "\n",
        "Using `shap`, you can:\n",
        "\n",
        "1. **Explain Individual Predictions**: Understand why a specific prediction was made for a particular instance.\n",
        "\n",
        "2. **Feature Importance**: Get an overview of which features are most important for the model's predictions.\n",
        "\n",
        "3. **Interaction Effects**: Discover interactions between features and how they impact predictions.\n",
        "\n",
        "4. **Global Interpretability**: Analyze the overall behavior of the model across the dataset.\n",
        "\n",
        "5. **Plot Visualizations**: Visualize Shapley values to gain insights.\n",
        "\n",
        "This library is particularly useful when you need to provide explanations for machine learning models, especially in fields where model interpretability and transparency are crucial (e.g., healthcare, finance, etc.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXrVGg1qn1HY"
      },
      "outputs": [],
      "source": [
        "!pip install shap\n",
        "import shap\n",
        "shap.initjs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lvom-1PYn1HY"
      },
      "outputs": [],
      "source": [
        "# explainer = shap.Explainer(logreg, X_train)\n",
        "# shap_values = explainer(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n45ghLWn1HZ"
      },
      "outputs": [],
      "source": [
        "# shap.plots.beeswarm(shap_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-In4vQuZn1HZ"
      },
      "outputs": [],
      "source": [
        "# shap.plots.bar(shap_values)\n",
        "# feature_names = X.columns.tolist()\n",
        "X_train_named = pd.DataFrame(X_train, columns=feature_names)\n",
        "X_test_named = pd.DataFrame(X_test, columns=feature_names)\n",
        "\n",
        "# Create a SHAP explainer using the training data with feature names\n",
        "explainer = shap.Explainer(logreg, X_train_named)\n",
        "\n",
        "# Calculate SHAP values for the test data\n",
        "shap_values = explainer(X_test_named)\n",
        "\n",
        "# Generate a SHAP bar plot\n",
        "shap.plots.bar(shap_values)\n",
        "X_train_named = pd.DataFrame(X_train, columns=feature_names)\n",
        "X_test_named = pd.DataFrame(X_test, columns=feature_names)\n",
        "\n",
        "# Create a SHAP explainer using the training data with feature names\n",
        "explainer = shap.Explainer(logreg, X_train_named)\n",
        "\n",
        "# Calculate SHAP values for the test data\n",
        "shap_values = explainer(X_test_named)\n",
        "\n",
        "# Generate a SHAP bar plot\n",
        "shap.plots.bar(shap_values)\n",
        "\n",
        "shap.plots.beeswarm(shap_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FzWXtSsZn1Ha"
      },
      "outputs": [],
      "source": [
        "shap.plots.bar(shap_values[4])\n",
        "\n",
        "shap.summary_plot(shap_values, X_test, feature_names=feature_names)\n",
        "# good - 104K Annual Income, 10 Years of Experience, Good sub_grade, 4% DTI very small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tESHRKNhn1Ha"
      },
      "outputs": [],
      "source": [
        "shap.plots.bar(shap_values[5])\n",
        "# not paying back - 40K Annual Income, 0 Years of Experience, not good sub_grade, 2% DTI very small but does make sense since probably started to work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wByTMrxpn1Ha"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtRQQlBDn1Hb"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q06LT_EHn1Hb"
      },
      "outputs": [],
      "source": [
        "pipeline_sgdlogreg = Pipeline([\n",
        "    ('imputer', SimpleImputer(copy=False)), # Mean imputation by default\n",
        "    ('scaler', StandardScaler(copy=False)),\n",
        "    ('model', SGDClassifier(loss='log_loss', max_iter=1000, tol=1e-3, random_state=1, warm_start=True))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzYnufr2n1Hb"
      },
      "outputs": [],
      "source": [
        "param_grid_sgdlogreg = {\n",
        "    # 'loss': ['log_loss'],\n",
        "    'model__alpha': [10**-5, 10**-2, 10**1],\n",
        "    'model__penalty': ['l1', 'l2']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMxoN6_In1Hc"
      },
      "outputs": [],
      "source": [
        "grid_sgdlogreg = GridSearchCV(estimator=pipeline_sgdlogreg, param_grid=param_grid_sgdlogreg, scoring='roc_auc', n_jobs=1, pre_dispatch=1, cv=5, verbose=1, return_train_score=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scjONPQBn1Hc"
      },
      "outputs": [],
      "source": [
        "grid_sgdlogreg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zmb7HNTn1Hc"
      },
      "outputs": [],
      "source": [
        "grid_sgdlogreg.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EoepWwnn1Hc"
      },
      "outputs": [],
      "source": [
        "grid_sgdlogreg.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFasN828n1Hc"
      },
      "source": [
        "## Random forest classifier\n",
        "<a id=\"8.2\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZPWe7own1Hc"
      },
      "source": [
        "Next we train a random forest model. Note that data standardization is not necessary for a random forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akdYusBqn1Hc"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQpKI3Zyn1Hd"
      },
      "outputs": [],
      "source": [
        "pipeline_rfc = Pipeline([\n",
        "    ('imputer', SimpleImputer(copy=False)),\n",
        "    ('model', RandomForestClassifier(n_jobs=-1, random_state=1))\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpjQ5docn1Hd"
      },
      "source": [
        "The random forest takes very long to train, so we don't test different hyperparameter choices. We'll still use `GridSearchCV` for the sake of consistency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsPVoL1Ln1Hd"
      },
      "outputs": [],
      "source": [
        "param_grid_rfc = {\n",
        "    'model__n_estimators': [50] # The number of randomized trees to build\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hzl3J5un1Hd"
      },
      "source": [
        "The AUROC will always improve (with decreasing gains) as the number of estimators increases, but it's not necessarily worth the extra training time and model complexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRAnQFukn1Hd"
      },
      "outputs": [],
      "source": [
        "grid_rfc = GridSearchCV(estimator=pipeline_rfc, param_grid=param_grid_rfc, scoring='roc_auc', n_jobs=1, pre_dispatch=1, cv=5, verbose=1, return_train_score=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05xmPan8n1He"
      },
      "outputs": [],
      "source": [
        "grid_rfc.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UNPq_ZMn1He"
      },
      "source": [
        "Mean cross-validated AUROC score of the random forest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4RK47vin1He"
      },
      "outputs": [],
      "source": [
        "grid_rfc.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB9okHkVn1Hf"
      },
      "source": [
        "Not quite as good as logistic regression, at least according to this metric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8g03bfRZn1Hf"
      },
      "source": [
        "## K - Nearest Neighbors\n",
        "<a id=\"8.3\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSkfzekMn1Hf"
      },
      "source": [
        "Next we try K - Nearest Neighbors. We need to reduce the number of variables to 10 or fewer ([reference](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm#Dimension_reduction)) for kNN to perform well. We'll use LDA for dimension reduction. The number of component variables to keep is a hyperparameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bh2atC5Un1Hf"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8olSZ72n1Hg"
      },
      "outputs": [],
      "source": [
        "pipeline_knn = Pipeline([\n",
        "    ('imputer', SimpleImputer(copy=False)),\n",
        "    ('scaler', StandardScaler(copy=False)),\n",
        "    ('lda', LinearDiscriminantAnalysis()),\n",
        "    ('model', KNeighborsClassifier(n_jobs=-1))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2xkfrx4n1Hg"
      },
      "outputs": [],
      "source": [
        "param_grid_knn = {\n",
        "    'lda__n_components': [1], # Number of LDA components to keep\n",
        "    'model__n_neighbors': [5, 25, 125] # The 'k' in k-nearest neighbors\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_6RSQmzn1Hg"
      },
      "outputs": [],
      "source": [
        "grid_knn = GridSearchCV(estimator=pipeline_knn, param_grid=param_grid_knn, scoring='roc_auc', n_jobs=1, pre_dispatch=1, cv=5, verbose=1, return_train_score=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6MKHTWCn1Hg"
      },
      "outputs": [],
      "source": [
        "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "# param_grid = {'n_components': [1, 2, 3, 4]}  # Adjust the range as needed\n",
        "# grid_search = GridSearchCV(LDA(), param_grid)\n",
        "\n",
        "grid_knn.fit(X_train, y_train)\n",
        "\n",
        "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "# param_grid = {'n_components': [1, 2, 3, 4]}  # Adjust the range as needed\n",
        "# grid_search = GridSearchCV(LDA(), param_grid)\n",
        "\n",
        "# grid_search.fit(X_train, y_train)  # Corrected line\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLgSd9vBn1Hh"
      },
      "source": [
        "Mean cross-validated AUROC score of the best model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9L2D7kxn1Hi"
      },
      "outputs": [],
      "source": [
        "grid_knn.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5esyXgb_n1Hi"
      },
      "source": [
        "Best hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vB18VV1jn1Hi"
      },
      "outputs": [],
      "source": [
        "grid_knn.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi3Q3D5Tn1Hi"
      },
      "source": [
        "Only 1 LDA components are necessary for kNN to perform almost as well as logistic regression!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tlz7VJVSn1Hi"
      },
      "source": [
        "## Tune hyperparameters on the chosen model more finely\n",
        "<a id=\"8.4\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQOLJrzln1Hi"
      },
      "source": [
        "The three models performed quite similarly according to the AUROC:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDPwWfp4n1Hi"
      },
      "outputs": [],
      "source": [
        "print('Cross-validated AUROC scores')\n",
        "print(grid_sgdlogreg.best_score_, '- Logistic regression')\n",
        "print(grid_rfc.best_score_, '- Random forest')\n",
        "print(grid_knn.best_score_, '- k-nearest neighbors')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck7bDrhYn1Hj"
      },
      "source": [
        "Logistic regression squeaked out ahead, and coupled with the fact that `SGDClassifier` trains much faster than the other two models, we'll select logistic regression as our final model. Now we'll tune the hyperparameters more finely."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvoD0S7Tn1Hj"
      },
      "outputs": [],
      "source": [
        "param_grid_sgdlogreg = {\n",
        "    'model__alpha': np.logspace(-4.5, 0.5, 11), # Fills in the gaps between 10^-5 and 10^1\n",
        "    'model__penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "print(param_grid_sgdlogreg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_dySnDjn1Hj"
      },
      "outputs": [],
      "source": [
        "grid_sgdlogreg = GridSearchCV(estimator=pipeline_sgdlogreg, param_grid=param_grid_sgdlogreg, scoring='roc_auc', n_jobs=1, pre_dispatch=1, cv=5, verbose=1, return_train_score=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xf1heaRDn1Hj"
      },
      "outputs": [],
      "source": [
        "grid_sgdlogreg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytueU0edn1Hk"
      },
      "source": [
        "Mean cross-validated AUROC score of the best model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Qy0860fn1Hk"
      },
      "outputs": [],
      "source": [
        "grid_sgdlogreg.best_score_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTb98Qhin1Hl"
      },
      "source": [
        "Best hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwFxU1non1Hl"
      },
      "outputs": [],
      "source": [
        "grid_sgdlogreg.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUxz3Q94n1Hl"
      },
      "source": [
        "These are the optimal hyperparameters for logistic regression!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoj6MyC1n1Hl"
      },
      "source": [
        "## Test set evaluation\n",
        "<a id=\"8.5\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGnqBnJTn1Hm"
      },
      "source": [
        "Now we can finally see how our chosen model performs on the test data (the most recent 10% of the loans)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZZNtsUbn1Hn"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjPZIcNBn1Ho"
      },
      "outputs": [],
      "source": [
        "y_score = grid_sgdlogreg.predict_proba(X_test)[:,1]\n",
        "roc_auc_score(y_test, y_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_31pt__n1Hp"
      },
      "source": [
        "The numeric value above, is the test set AUROC score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00kyUQjmn1Hp"
      },
      "source": [
        "Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqAQdiJrn1Hq"
      },
      "outputs": [],
      "source": [
        "# # Naive Bayes\n",
        "# nb_classifier = GaussianNB()\n",
        "# nb_classifier.fit(X_train, y_train)\n",
        "# nb_predictions = nb_classifier.predict(X_test)\n",
        "# nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
        "# print(f\"Naive Bayes Accuracy: {nb_accuracy}\")\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# # Initialize Naive Bayes Classifier\n",
        "# nb_classifier = GaussianNB()\n",
        "\n",
        "# # Train the Model\n",
        "# nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# # Predict Using the Model\n",
        "# nb_predictions = nb_classifier.predict(X_test)\n",
        "\n",
        "# # Evaluate the Model (Accuracy)\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# nb_accuracy = accuracy_score(y_test, nb_predictions)\n",
        "# print(f\"Naive Bayes Accuracy: {nb_accuracy}\")\n",
        "\n",
        "# from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Initialize Naive Bayes Classifier\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Train the Model\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict Probability Estimates\n",
        "y_proba = nb_classifier.predict_proba(X_test)\n",
        "\n",
        "# Set your custom threshold\n",
        "threshold = 0.87  # Adjust this value as needed\n",
        "\n",
        "# Apply the threshold to classify samples\n",
        "y_pred = (y_proba[:, 1] > threshold).astype(int)\n",
        "\n",
        "# Evaluate the Model (Accuracy)\n",
        "from sklearn.metrics import accuracy_score\n",
        "nb_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Naive Bayes Accuracy: {nb_accuracy}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOGCTYIZn1Hq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Confusion Matrix for Naive Bayes\n",
        "# nb_cm = confusion_matrix(y_test, nb_predictions)\n",
        "# nb_cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# # Plot Confusion Matrix\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.title(\"Confusion Matrix - Naive Bayes\")\n",
        "# sns.heatmap(nb_cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "# plt.xlabel(\"Predicted\")\n",
        "# plt.ylabel(\"Actual\")\n",
        "# plt.show()\n",
        "\n",
        "nb_cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "total = np.sum(nb_cm)\n",
        "\n",
        "percentage_matrix = nb_cm / total * 100\n",
        "\n",
        "sns.set(rc = {'figure.figsize':(15,8)})\n",
        "plt.title(\"Confusion Matrix - Naive Bayes\")\n",
        "sns.heatmap(percentage_matrix, annot=True, cmap='YlGnBu', fmt='.2f', linewidths=.5)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Classification Report for Naive Bayes\n",
        "# nb_classification_report = classification_report(y_test, nb_predictions)\n",
        "nb_classification_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Print Classification Report\n",
        "print(\"Classification Report - Naive Bayes:\")\n",
        "print(nb_classification_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lz-2LylDn1Hq"
      },
      "outputs": [],
      "source": [
        "# from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# # Initialize Multinomial Naive Bayes Classifier\n",
        "# mnb_classifier = MultinomialNB()\n",
        "\n",
        "# # Train the Model\n",
        "# mnb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# # Predict Using the Model\n",
        "# mnb_predictions = mnb_classifier.predict(X_test)\n",
        "\n",
        "# # Evaluate the Model (Accuracy)\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# mnb_accuracy = accuracy_score(y_test, mnb_predictions)\n",
        "# print(f\"Multinomial Naive Bayes Accuracy: {mnb_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYywVKSen1Hq"
      },
      "outputs": [],
      "source": [
        "# from sklearn.svm import SVC\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# # Initialize the SVM classifier\n",
        "# svm_classifier = SVC()\n",
        "\n",
        "# # Fit the SVM classifier on the training data\n",
        "# svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# # Predict on the test data\n",
        "# y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# # Calculate the accuracy of the model\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# print(f'Accuracy: {accuracy}')\n",
        "\n",
        "\n",
        "\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# # Initialize the SVM classifier\n",
        "# svm_classifier = SVC(probability=True)  # Set probability=True to enable decision_function\n",
        "\n",
        "# # Fit the SVM classifier on the training data\n",
        "# svm_classifier.fit(X_train, y_train)\n",
        "\n",
        "# # Get the decision function scores\n",
        "# decision_scores = svm_classifier.decision_function(X_test)\n",
        "\n",
        "# # Set your custom threshold\n",
        "# threshold = 0.05  # Adjust this value as needed\n",
        "\n",
        "# # Apply the threshold to classify samples\n",
        "# y_pred = (decision_scores > threshold).astype(int)\n",
        "\n",
        "# # y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# # Calculate the accuracy of the model\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# print(f'Accuracy: {accuracy}')\n",
        "\n",
        "\n",
        "\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Assuming X_train, y_train are your training data\n",
        "sampler = RandomUnderSampler(random_state=42)\n",
        "X_resampled, y_resampled = sampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# Initialize the SVM classifier\n",
        "svm_classifier = SVC()\n",
        "\n",
        "# Fit the SVM classifier on the resampled training data\n",
        "svm_classifier.fit(X_resampled, y_resampled)\n",
        "\n",
        "\n",
        "\n",
        "# Get the decision function scores\n",
        "decision_scores = svm_classifier.decision_function(X_test)\n",
        "\n",
        "# Set your custom threshold\n",
        "threshold = 0.6  # Adjust this value as needed\n",
        "\n",
        "# Apply the threshold to classify samples\n",
        "y_pred = (decision_scores > threshold).astype(int)\n",
        "\n",
        "# y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "# Predict on the test data\n",
        "# y_pred = svm_classifier.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2tjPq83n1Hr"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Define ROC curve variables\n",
        "# fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# # Plot confusion matrix\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "# plt.title('Confusion Matrix')\n",
        "# plt.colorbar()\n",
        "# classes = ['0', '1']  # Assuming 0 and 1 are your class labels\n",
        "# plt.xticks([0, 1], classes, rotation=45)\n",
        "# plt.yticks([0, 1], classes)\n",
        "# plt.ylabel('True label')\n",
        "# plt.xlabel('Predicted label')\n",
        "# plt.show()\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "# plt.figure(figsize=(8, 6))\n",
        "# plt.title(\"Confusion Matrix - SVM\")\n",
        "# sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "# plt.xlabel(\"Predicted\")\n",
        "# plt.ylabel(\"Actual\")\n",
        "# plt.show()\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "total = np.sum(cm)\n",
        "\n",
        "percentage_matrix = cm / total * 100\n",
        "\n",
        "sns.set(rc = {'figure.figsize':(15,8)})\n",
        "plt.title(\"Confusion Matrix - SVM\")\n",
        "sns.heatmap(percentage_matrix, annot=True, cmap='YlGnBu', fmt='.2f', linewidths=.5)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBsLWmfXn1Hr"
      },
      "source": [
        "# Conclusion\n",
        "<a id=\"9\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h472qS6n1Hs"
      },
      "source": [
        "We applied machine learning methods to predict the probability that a requested loan on LendingClub will charge off. After training and evaluating 5 different models (logistic regression, random forest, and k-nearest neighbors, Gaussian Naive Bayes, & SVM), we found that all 5 performed similarly (that is, with some level of approximation) according to a cross-validated AUROC score on the training data. We selected logistic regression (with ridge penalty) because it was the fastest model to train.\n",
        "\n",
        "This model, while far from perfect, can provide a somewhat informed prediction of the likelihood that a loan will charge off, using only data available to potential investors before the loan is fully funded.\n",
        "\n",
        "We also found that, according to linear measures of correlation between the predictors and the response, the most important variables for predicting charge-off are the loan interest rate and term, and the borrower's FICO score and debt-to-income ratio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K4rlkFFan1Hs"
      },
      "source": [
        "<div style=\"padding: 20px;\n",
        "            color: #435334;\n",
        "            margin: 10px;\n",
        "            font-size: 150%;\n",
        "            display: fill;\n",
        "            border-radius: 10px;\n",
        "            border-style: solid;\n",
        "            border-color: #176B87;\n",
        "            background-color: #A7EDE7;\n",
        "            overflow: hidden;\n",
        "            font-weight: 700;\n",
        "            text-align: center;\">\n",
        "END\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
